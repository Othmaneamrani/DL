{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab13: Stock price prediction\n",
    "### Réalisé par: Your Name  email@\n",
    "### EMSI 2024/2025\n",
    "\n",
    "\n",
    "# T.A.F\n",
    "1. Démarrer \n",
    "2. Analyser\n",
    "3. Améliorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T11:08:06.863088900Z",
     "start_time": "2024-11-27T11:08:06.811789800Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Dataset\n",
    " url = 'https://raw.githubusercontent.com/mwitiderrick/stockprice/master/NSE-TATAGLOBAL.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T11:08:12.135641700Z",
     "start_time": "2024-11-27T11:08:06.871366400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Date    Open    High     Low    Last   Close  \\\n",
      "0     2018-09-28  234.05  235.95  230.20  233.50  233.75   \n",
      "1     2018-09-27  234.55  236.80  231.10  233.80  233.25   \n",
      "2     2018-09-26  240.00  240.00  232.50  235.00  234.25   \n",
      "3     2018-09-25  233.30  236.75  232.00  236.25  236.10   \n",
      "4     2018-09-24  233.55  239.20  230.75  234.00  233.30   \n",
      "...          ...     ...     ...     ...     ...     ...   \n",
      "2030  2010-07-27  117.60  119.50  112.00  118.80  118.65   \n",
      "2031  2010-07-26  120.10  121.00  117.10  117.10  117.60   \n",
      "2032  2010-07-23  121.80  121.95  120.25  120.35  120.65   \n",
      "2033  2010-07-22  120.30  122.00  120.25  120.75  120.90   \n",
      "2034  2010-07-21  122.10  123.00  121.05  121.10  121.55   \n",
      "\n",
      "      Total Trade Quantity  Turnover (Lacs)  \n",
      "0                  3069914          7162.35  \n",
      "1                  5082859         11859.95  \n",
      "2                  2240909          5248.60  \n",
      "3                  2349368          5503.90  \n",
      "4                  3423509          7999.55  \n",
      "...                    ...              ...  \n",
      "2030                586100           694.98  \n",
      "2031                658440           780.01  \n",
      "2032                281312           340.31  \n",
      "2033                293312           355.17  \n",
      "2034                658666           803.56  \n",
      "\n",
      "[2035 rows x 8 columns]\n",
      "[[0.6202352 ]\n",
      " [0.62226277]\n",
      " [0.64436334]\n",
      " ...\n",
      " [0.16504461]\n",
      " [0.15896188]\n",
      " [0.16626115]]\n"
     ]
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/mwitiderrick/stockprice/master/NSE-TATAGLOBAL.csv'\n",
    "dataset_train = pd.read_csv(url)\n",
    "training_set = dataset_train.iloc[:, 1:2].values\n",
    "print(dataset_train)\n",
    "# Data transformation\n",
    "sc = MinMaxScaler(feature_range=(0,1))\n",
    "training_set_scaled = sc.fit_transform(training_set)\n",
    "print(training_set_scaled)\n",
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(60, 2035):\n",
    "    X_train.append(training_set_scaled[i-60:i, 0])\n",
    "    y_train.append(training_set_scaled[i, 0])\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T11:08:12.566105600Z",
     "start_time": "2024-11-27T11:08:12.130043Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asmae\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Initialize the RNN model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first SimpleRNN layer with return_sequences=True\n",
    "model.add(SimpleRNN(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Add the second SimpleRNN layer with return_sequences=True\n",
    "model.add(SimpleRNN(units=50, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Add the third SimpleRNN layer with return_sequences=True\n",
    "model.add(SimpleRNN(units=50, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Add the fourth SimpleRNN layer without return_sequences\n",
    "model.add(SimpleRNN(units=50))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Add the Dense output layer\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T11:10:08.603658600Z",
     "start_time": "2024-11-27T11:08:12.560130Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001B[1m62/62\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 53ms/step - loss: 0.4569\n",
      "Epoch 2/30\n",
      "\u001B[1m62/62\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 54ms/step - loss: 0.2111\n",
      "Epoch 3/30\n",
      "\u001B[1m62/62\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 55ms/step - loss: 0.1306\n",
      "Epoch 4/30\n",
      "\u001B[1m62/62\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 55ms/step - loss: 0.0731\n",
      "Epoch 5/30\n",
      "\u001B[1m62/62\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 54ms/step - loss: 0.0509\n",
      "Epoch 6/30\n",
      "\u001B[1m62/62\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 55ms/step - loss: 0.0397\n",
      "Epoch 7/30\n",
      "\u001B[1m62/62\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 54ms/step - loss: 0.0349\n",
      "Epoch 8/30\n",
      "\u001B[1m62/62\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 54ms/step - loss: 0.0286\n",
      "Epoch 9/30\n",
      "\u001B[1m62/62\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 55ms/step - loss: 0.0222\n",
      "Epoch 10/30\n",
      "\u001B[1m62/62\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 54ms/step - loss: 0.0184\n",
      "Epoch 11/30\n",
      "\u001B[1m62/62\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 55ms/step - loss: 0.0157\n",
      "Epoch 12/30\n",
      "\u001B[1m62/62\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 54ms/step - loss: 0.0129\n",
      "Epoch 13/30\n",
      "\u001B[1m62/62\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 54ms/step - loss: 0.0120\n",
      "Epoch 14/30\n",
      "\u001B[1m62/62\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 55ms/step - loss: 0.0103\n",
      "Epoch 15/30\n",
      "\u001B[1m62/62\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 55ms/step - loss: 0.0089\n",
      "Epoch 16/30\n",
      "\u001B[1m62/62\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 54ms/step - loss: 0.0073\n",
      "Epoch 17/30\n",
      "\u001B[1m62/62\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 55ms/step - loss: 0.0075\n",
      "Epoch 18/30\n",
      "\u001B[1m62/62\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 57ms/step - loss: 0.0063\n",
      "Epoch 19/30\n",
      "\u001B[1m62/62\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 55ms/step - loss: 0.0067\n",
      "Epoch 20/30\n",
      "\u001B[1m62/62\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 58ms/step - loss: 0.0056\n",
      "Epoch 21/30\n",
      "\u001B[1m62/62\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 55ms/step - loss: 0.0056\n",
      "Epoch 22/30\n",
      "\u001B[1m62/62\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 56ms/step - loss: 0.0042\n",
      "Epoch 23/30\n",
      "\u001B[1m62/62\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 54ms/step - loss: 0.0045\n",
      "Epoch 24/30\n",
      "\u001B[1m62/62\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 56ms/step - loss: 0.0041\n",
      "Epoch 25/30\n",
      "\u001B[1m62/62\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 55ms/step - loss: 0.0038\n",
      "Epoch 26/30\n",
      "\u001B[1m62/62\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 56ms/step - loss: 0.0036\n",
      "Epoch 27/30\n",
      "\u001B[1m62/62\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 56ms/step - loss: 0.0034\n",
      "Epoch 28/30\n",
      "\u001B[1m62/62\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 54ms/step - loss: 0.0042\n",
      "Epoch 29/30\n",
      "\u001B[1m62/62\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 55ms/step - loss: 0.0029\n",
      "Epoch 30/30\n",
      "\u001B[1m62/62\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 55ms/step - loss: 0.0033\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.history.History at 0x22a09381690>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs=30,batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: test\n",
    "url = 'https://raw.githubusercontent.com/mwitiderrick/stockprice/master/tatatest.csv'"
   ]
  },
  {
   "cell_type": "raw",
   "source": [
    "url = 'https://raw.githubusercontent.com/mwitiderrick/stockprice/master/tatatest.csv'\n",
    "dataset_test = pd.read_csv(url)\n",
    "real_stock_price = dataset_test.iloc[:, 1:2].values\n",
    "dataset_total = pd.concat((dataset_train['Open'], dataset_test['Open']), axis = 0)\n",
    "inputs = dataset_total[len(dataset_total) - len(dataset_test) - 60:].values\n",
    "inputs = inputs.reshape(-1,1)\n",
    "inputs = sc.transform(inputs)\n",
    "X_test = []\n",
    "for i in range(60, 76):\n",
    "    X_test.append(inputs[i-60:i, 0])\n",
    "X_test = np.array(X_test)\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "# Prediction\n",
    "predicted_stock_price = model.predict(X_test)\n",
    "predicted_stock_price = sc.inverse_transform(predicted_stock_price)\n",
    "plt.plot(real_stock_price, color = 'black', label = 'TATA Stock Price')\n",
    "plt.plot(predicted_stock_price, color = 'green', label = 'Predicted TATA Stock Price')\n",
    "plt.title('TATA Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('TATA Stock Price')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T11:10:08.643302600Z",
     "start_time": "2024-11-27T11:10:08.607521800Z"
    }
   },
   "outputs": [],
   "source": [
    "#model.save('tata_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bousmah_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
